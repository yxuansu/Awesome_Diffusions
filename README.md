## I am learning diffusion models. This list keeps track of the papers that I enjoy reading :-)

****

<span id='all_catelogue'/>

### Catalogue:
* <a href='#vision'>1. Vision</a>
    * <a href='#image_generation'>1.1. Text-to-Image Generation</a>
    * <a href='#object_detection'>1.2. Object Detection</a>
* <a href='#language'>2. Language</a>
    * <a href='#text_generation'>2.1. Text Generation</a>
* <a href='#vision_and_language'>3. Vision and Language</a>
    * <a href='#image_captioning'>3.1. Image Captioning</a>


****

<span id='vision'/>

#### 1. Vision: <a href='#all_catelogue'>[Back to Top]</a>

<span id='image_generation'/>

#### 1.1. Text-to-Image Generation: 
* **"AltCLIP: Altering the Language Encoder in CLIP for Extended Language Capabilities"** Zhongzhi Chen, Guang Liu, Bo-Wen Zhang, Fulong Ye, Qinghong Yang, Ledell Wu; [[arxiv]](https://arxiv.org/abs/2211.06679)[[code]](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/AltDiffusion)
* **"Hierarchical Text-Conditional Image Generation with CLIP Latents"** Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, Mark Chen; [[arxiv]](https://arxiv.org/abs/2204.06125)



<span id='object_detection'/>

#### 1.2. Object Detection: 

* **"DiffusionDet: Diffusion Model for Object Detection"** Shoufa Chen, Peize Sun, Yibing Song, Ping Luo; [[arxiv]](https://arxiv.org/abs/2211.09788)[[code]](https://github.com/ShoufaChen/DiffusionDet)


****

<span id='language'/>

#### 2. Language: <a href='#all_catelogue'>[Back to Top]</a>

<span id='text_generation'/>

#### 2.1. Text Generation: 

* **"Diffusion-LM Improves Controllable Text Generation"** Xiang Lisa Li, John Thickstun, Ishaan Gulrajani, Percy Liang, Tatsunori B. Hashimoto; [[arxiv]](https://arxiv.org/abs/2205.14217)[[code]](https://github.com/xiangli1999/diffusion-lm)
* **"DiffusionBERT: Improving Generative Masked Language Models with Diffusion Models"** Zhengfu He, Tianxiang Sun, Kuanning Wang, Xuanjing Huang, Xipeng Qiu; [[arxiv]](https://arxiv.org/pdf/2211.15029.pdf)[[code]](https://github.com/Hzfinfdu/Diffusion-BERT).
* **"GENIE: Large Scale Pre-training for Generation with Diffusion Model"** Zhenghao Lin, Yeyun Gong, Yelong Shen, Tong Wu, Zhihao Fan, Chen Lin, Weizhu Chen, Nan Duan; [[arxiv]](https://arxiv.org/pdf/2212.11685.pdf)
* **"Difformer: Empowering Diffusion Model on Embedding Space for Text Generation"** Zhujin Gao, Junliang Guo, Xu Tan, Yongxin Zhu, Fang Zhang, Jiang Bian, Linli Xu; [[arxiv]](https://download.arxiv.org/pdf/2212.09412v1)
* **"DiffuSeq: Sequence to Sequence Text Generation with Diffusion Models"** Shansan Gong, Mukai Li, Jiangtao Feng, Zhiyong Wu, Lingpeng Kong; [[arxiv]](https://arxiv.org/pdf/2210.08933.pdf)[[code]](https://github.com/Shark-NLP/DiffuSeq)


****

<span id='vision_and_language'/>

#### 3. Vision and Language: <a href='#all_catelogue'>[Back to Top]</a>

<span id='image_captioning'/>

#### 3.1. Image Captioning: 

* **"Exploring Discrete Diffusion Models for Image Captioning"** Zixin Zhu, Yixuan Wei, Jianfeng Wang, Zhe Gan, Zheng Zhang, Le Wang, Gang Hua, Lijuan Wang, Zicheng Liu, Han Hu; [[arxiv]](https://arxiv.org/abs/2211.11694)[[code]](https://github.com/buxiangzhiren/DDCap)




